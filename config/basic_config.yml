base_model: TinyLlama/TinyLlama-1.1B-Chat-v1.0
model_type: LlamaForCausalLM
tokenizer_type: LlamaTokenizer

datasets:
  - path: jaydenccc/AI_Storyteller_Dataset
    type:
      system_prompt: ""
      field_system: system
      field_instruction: synopsis
      field_output: short_story
      format: "<|user|>\n {instruction} </s>\n <|assistant|>"
      no_input_format: "<|user|>\n {instruction} </s>\n <|assistant|>"

output_dir: ./outputs/TinyLlama-1.1B-Chat-v1.0_Story_Teller

sequence_len: 2048
bf16: auto
tf32: false

adapter: lora
lora_r: 32
lora_alpha: 16
lora_dropout: 0.05
lora_target_linear: true

gradient_accumulation_steps: 4
micro_batch_size: 2
num_epochs: 4
optimizer: adamw_bnb_8bit
lr_scheduler: cosine
learning_rate: 0.0002

gradient_checkpointing: true

logging_steps: 1